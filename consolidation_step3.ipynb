{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18706,
     "status": "ok",
     "timestamp": 1687772555582,
     "user": {
      "displayName": "Khaled Bagh",
      "userId": "04510009910654484115"
     },
     "user_tz": -120
    },
    "id": "CkHbVr1seA9A",
    "outputId": "d6d91db2-e8d9-46dd-91cc-83139e525b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2022.12.1)\n",
      "Collecting dask\n",
      "  Downloading dask-2023.6.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: distributed in /usr/local/lib/python3.10/dist-packages (2022.12.1)\n",
      "Collecting distributed\n",
      "  Downloading distributed-2023.6.0-py3-none-any.whl (976 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m976.1/976.1 kB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask) (8.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask) (23.1)\n",
      "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask) (6.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask) (0.12.0)\n",
      "Collecting importlib-metadata>=4.13.0 (from dask)\n",
      "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed) (3.1.2)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed) (1.0.5)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed) (5.9.5)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed) (1.7.0)\n",
      "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed) (6.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed) (1.26.16)\n",
      "Requirement already satisfied: zict>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed) (2.1.3)\n",
      "Installing collected packages: importlib-metadata, dask, distributed\n",
      "  Attempting uninstall: dask\n",
      "    Found existing installation: dask 2022.12.1\n",
      "    Uninstalling dask-2022.12.1:\n",
      "      Successfully uninstalled dask-2022.12.1\n",
      "  Attempting uninstall: distributed\n",
      "    Found existing installation: distributed 2022.12.1\n",
      "    Uninstalling distributed-2022.12.1:\n",
      "      Successfully uninstalled distributed-2022.12.1\n",
      "Successfully installed dask-2023.6.0 distributed-2023.6.0 importlib-metadata-6.7.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2023.6.0)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (23.1)\n",
      "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.7.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.22.4)\n",
      "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.5.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->dask[dataframe]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->dask[dataframe]) (2022.7.1)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3->dask[dataframe]) (1.16.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting mne\n",
      "  Downloading mne-1.4.2-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from mne) (1.10.1)\n",
      "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.65.0)\n",
      "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.6.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (2.8.2)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.27.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
      "Installing collected packages: mne\n",
      "Successfully installed mne-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install dask distributed --upgrade\n",
    "!pip install \"dask[dataframe]\" --upgrade\n",
    "!pip install mne --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rb3gWQVtea8i"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import tensorflow as tf\n",
    "\n",
    "# note the code will not overwrite existing output file in case of rerun\n",
    "\n",
    "# file path seperator (system based, windows \\\\ and linux /)\n",
    "seperator = \"/\"\n",
    "\n",
    "# channels of intrest\n",
    "csv_channel_names = ['E1','E2',\\\n",
    "                                  'E3','E4','E5','E6','E7','E8','E9','E10','E11','E12','E13','E14','E15','E16','E18','E19','E20','E21','E22','E23','E24','E25',\\\n",
    "                                  'E26','E27','E28','E29','E30','E31','E32','E33','E34','E35','E36','E37','E38','E39','E40','E41','E42','E44','E45','E46','E47',\\\n",
    "                                  'E50','E51','E52','E53','E54','E55','E57','E58','E59','E60','E61','E62','E64','E65','E66','E67','E69','E70','E71','E72','E74','E75',\\\n",
    "                                  'E76','E77','E78','E79','E80','E82','E83','E84','E85','E86','E87','E89','E90','E91','E92','E93','E95','E96','E97','E98','E100','E101',\\\n",
    "                                  'E102','E103','E104','E105','E106','E108','E109','E110','E111','E112','E114','E115','E116','E117','E118','E121','E122','E123','E124']\n",
    "\n",
    "# frequency ranges with their name\n",
    "freqs = {\"delta\": [1, 4],\n",
    "                  \"theta\": [4, 8],\n",
    "                  \"alpha\": [8, 12],\n",
    "                  \"beta\": [12, 30],\n",
    "                  \"gamma\": [30,70],\n",
    "                  \"ALL\": [1, 70]}\n",
    "\n",
    "# name of the model and it's input shape \n",
    "models = {\"CNN\": [len(csv_channel_names), 350]}\n",
    "\n",
    "# data location\n",
    "foldername = r\"\"\n",
    "# output location\n",
    "outputPath = r\"\"\n",
    "\n",
    "# disorders of intrest\n",
    "disorders = ['HBN', 'MDD']\n",
    "\n",
    "# channel grouping into ROI\n",
    "channels = {\n",
    "    \"TR\":[35,34,52,44,43,42,39,38,37,33,32,41,45,46,47,48,49,28,27],\n",
    "    \"OR\":[53,54,55,56,57,58,59,60,61,62,63,64,65,66,67],\n",
    "    \"FR\":[26,23,22,19,18,11,25,24,21,20,17,16,15,14,10,31,24],\n",
    "    \"Center\":[36, 29, 12,99,94,93,78,72,71,51,50,30,6,5],\n",
    "    \"FL\":[108,107,1,0,104,9,8,7,3,4,2],\n",
    "    \"OL\":[70,85,84,81,80,79,76,75,74,73,69,68],\n",
    "    \"TL\":[106,103,102,100,97,96,95,91,98,92,83,77,90,89,88,87,86,82]}\n",
    "\n",
    "# ROIs\n",
    "roi_label = ['TR','OR','FR','Center','FL','OL','TL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9140654,
     "status": "ok",
     "timestamp": 1687781791876,
     "user": {
      "displayName": "Khaled Bagh",
      "userId": "04510009910654484115"
     },
     "user_tz": -120
    },
    "id": "aPvCCSPaeeRB",
    "outputId": "bfa22077-6ba7-4c22-ee8d-186558cc64f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HBN\n",
      "NDAREH074NG8_RestingState_data.csv\n",
      "NDARGL800LDW_RestingState_data.csv\n",
      "NDARDX872VH6_RestingState_data.csv\n",
      "NDARAA075AMK_RestingState_data.csv\n",
      "NDARCY178KJP_RestingState_data.csvNDARBY518PRN_RestingState_data.csv\n",
      "\n",
      "NDARBL117AUV_RestingState_data.csv\n",
      "NDARAC904DMU_RestingState_data.csv\n",
      "NDARCT472UJ7_RestingState_data.csv\n",
      "NDARCJ363KLE_RestingState_data.csv\n",
      "NDAREF389RY2_RestingState_data.csv\n",
      "NDARCX053GU5_RestingState_data.csv\n",
      "NDAREW201WD9_RestingState_data.csv\n",
      "NDARBU928LV0_RestingState_data.csv\n",
      "NDARBA521RA8_RestingState_data.csv\n",
      "NDARAU447JZH_RestingState_data.csv\n",
      "NDARGD507TDZ_RestingState_data.csv\n",
      "NDARFL411AT1_RestingState_data.csv\n",
      "NDARBH024NH2_RestingState_data.csv\n",
      "NDARFW292PBD_RestingState_data.csv\n",
      "NDARFY075REK_RestingState_data.csv\n",
      "NDARCW963FP9_RestingState_data.csv\n",
      "NDAREW976FNL_RestingState_data.csv\n",
      "NDAREM703YFD_RestingState_data.csv\n",
      "NDARDL511UND_RestingState_data.csv\n",
      "NDARDR296XHN_RestingState_data.csv\n",
      "NDARAM675UR8_RestingState_data.csv\n",
      "NDARDJ825GBP_RestingState_data.csv\n",
      "NDARCD401HGZ_RestingState_data.csv\n",
      "NDARET653TAM_RestingState_data.csv\n",
      "NDARGB441VVD_RestingState_data.csv\n",
      "NDARAV610EY3_RestingState_data.csv\n",
      "NDAREX065KJU_RestingState_data.csv\n",
      "NDARAE012DGA_RestingState_data.csv\n",
      "NDARDJ092YKH_RestingState_data.csv\n",
      "NDARBK082PDD_RestingState_data.csv\n",
      "NDARAM277WZT_RestingState_data.csv\n",
      "NDARFK610GY5_RestingState_data.csv\n",
      "NDAREU551GPC_RestingState_data.csv\n",
      "NDAREK549XUQ_RestingState_data.csv\n",
      "NDARGR875AXY_RestingState_data.csv\n",
      "NDARAN385MDH_RestingState_data.csv\n",
      "NDARCE721YB5_RestingState_data.csv\n",
      "NDARDN489EXJ_RestingState_data.csv\n",
      "NDARGG205WVN_RestingState_data.csv\n",
      "NDARJJ356DAL_RestingState_data.csv\n",
      "NDARGH790CEF_RestingState_data.csv\n",
      "NDARMH625WKL_RestingState_data.csv\n",
      "NDARHP924ZHW_RestingState_data.csv\n",
      "NDARMF508PA2_RestingState_data.csv\n",
      "NDARME930DE7_RestingState_data.csv\n",
      "NDARAX283MAK_RestingState_data.csv\n",
      "NDARGT682ZWN_RestingState_data.csv\n",
      "NDARJB355YHK_RestingState_data.csv\n",
      "NDARMW252AJW_RestingState_data.csv\n",
      "NDARJW315BUA_RestingState_data.csv\n",
      "NDARLA395AG8_RestingState_data.csv\n",
      "NDARHR443EHF_RestingState_data.csv\n",
      "NDARLF446MT5_RestingState_data.csv\n",
      "NDARKN509RP9_RestingState_data.csv\n",
      "NDARMC759CX3_RestingState_data.csv\n",
      "NDARHB764VZ2_RestingState_data.csv\n",
      "NDARGV956EGX_RestingState_data.csv\n",
      "NDARMZ518UH1_RestingState_data.csv\n",
      "NDARMD575AXD_RestingState_data.csv\n",
      "NDARJV377HG4_RestingState_data.csv\n",
      "NDARLX816JUZ_RestingState_data.csv\n",
      "NDARMM782KJK_RestingState_data.csv\n",
      "NDARKR010EN7_RestingState_data.csv\n",
      "NDARJM708VGE_RestingState_data.csv\n",
      "NDARJH441HJD_RestingState_data.csv\n",
      "NDARLA516PH1_RestingState_data.csv\n",
      "NDARKT811ATJ_RestingState_data.csv\n",
      "NDARLU111UYF_RestingState_data.csv\n",
      "NDARLU606ZDD_RestingState_data.csv\n",
      "NDARLC358CYJ_RestingState_data.csv\n",
      "NDARLX836EHJ_RestingState_data.csv\n",
      "NDARHV527DNK_RestingState_data.csv\n",
      "NDARMC760NEC_RestingState_data.csv\n",
      "NDARKH837TB2_RestingState_data.csv\n",
      "NDARLJ886BFK_RestingState_data.csv\n",
      "NDARHJ945PV0_RestingState_data.csv\n",
      "NDARGT022BEW_RestingState_data.csv\n",
      "NDARMY301WFK_RestingState_data.csv\n",
      "NDARMW178UDD_RestingState_data.csv\n",
      "NDARMT882AWE_RestingState_data.csv\n",
      "NDARGX443CEU_RestingState_data.csv\n",
      "NDARNG689AAP_RestingState_data.csv\n",
      "NDARHB000YF8_RestingState_data.csv\n",
      "NDARRV480PU1_RestingState_data.csv\n",
      "NDARJJ343TR0_RestingState_data.csv\n",
      "NDARRE333EKT_RestingState_data.csv\n",
      "NDARRD326KB9_RestingState_data.csv\n",
      "NDARKU278YRR_RestingState_data.csv\n",
      "NDARJZ089HVP_RestingState_data.csv\n",
      "NDARLZ104NDT_RestingState_data.csv\n",
      "NDARNT939YMG_RestingState_data.csv\n",
      "NDARRY280KNW_RestingState_data.csv\n",
      "NDARMV575DC1_RestingState_data.csv\n",
      "NDARRG199RU4_RestingState_data.csv\n",
      "NDARUF069EHR_RestingState_data.csv\n",
      "NDARTR840XP1_RestingState_data.csv\n",
      "NDARNU249EDF_RestingState_data.csv\n",
      "NDARRB338YZ0_RestingState_data.csv\n",
      "NDARYJ389DWX_RestingState_data.csv\n",
      "NDARPC817XZ5_RestingState_data.csv\n",
      "NDARLV387GP4_RestingState_data.csv\n",
      "NDARVP281CJ4_RestingState_data.csv\n",
      "NDARRG415BJM_RestingState_data.csv\n",
      "NDARUF152ARR_RestingState_data.csv\n",
      "NDARUR987CDM_RestingState_data.csv\n",
      "NDARUL250RA6_RestingState_data.csv\n",
      "NDARTH610GMK_RestingState_data.csv\n",
      "NDARWZ495PG4_RestingState_data.csv\n",
      "NDARTF566PYH_RestingState_data.csv\n",
      "NDARTU768MY1_RestingState_data.csv\n",
      "NDARUL456EER_RestingState_data.csv\n",
      "NDARVE724GEF_RestingState_data.csv\n",
      "NDARPE056ACA_RestingState_data.csv\n",
      "NDARTH473LF8_RestingState_data.csv\n",
      "NDARUG323DM3_RestingState_data.csv\n",
      "NDARUW816MP3_RestingState_data.csv\n",
      "NDARVG461LA2_RestingState_data.csv\n",
      "NDARPW482TVE_RestingState_data.csv\n",
      "NDARUP249AMD_RestingState_data.csv\n",
      "NDARRK882CLT_RestingState_data.csv\n",
      "NDARUG507AZX_RestingState_data.csv\n",
      "NDARTU777GVV_RestingState_data.csv\n",
      "NDARRY785GLM_RestingState_data.csv\n",
      "NDARUA421HT8_RestingState_data.csv\n",
      "NDARRZ199KNG_RestingState_data.csv\n",
      "NDARXX895FNJ_RestingState_data.csv\n",
      "NDARUM569EV1_RestingState_data.csv\n",
      "NDARRZ653HKY_RestingState_data.csv\n",
      "NDARTX934NH6_RestingState_data.csv\n",
      "NDARRV638MJV_RestingState_data.csv\n",
      "NDARPZ621ZLE_RestingState_data.csv\n",
      "NDARTN173MXV_RestingState_data.csv\n",
      "NDARVV248VW0_RestingState_data.csv\n",
      "NDARZG263HRK_RestingState_data.csv\n",
      "NDARZD415ZZ1_RestingState_data.csv\n",
      "NDARUF935UL3_RestingState_data.csv\n",
      "NDARZG690NHH_RestingState_data.csv\n",
      "NDARXH597ML1_RestingState_data.csv\n",
      "NDARUY811CYU_RestingState_data.csv\n",
      "NDARVL555VVA_RestingState_data.csv\n",
      "NDARXM571XCC_RestingState_data.csv\n",
      "NDARXJ696AMX_RestingState_data.csv\n",
      "NDARYL272HDW_RestingState_data.csv\n",
      "NDARXT792GY8_RestingState_data.csv\n",
      "NDARXU253JHC_RestingState_data.csv\n",
      "NDARYR771VED_RestingState_data.csv\n",
      "NDARXK462WRZ_RestingState_data.csv\n",
      "NDARYP516VUU_RestingState_data.csv\n",
      "NDARXV445NYZ_RestingState_data.csv\n",
      "NDARYL758JGG_RestingState_data.csv\n",
      "NDARYU620RH9_RestingState_data.csv\n",
      "NDARXC418YG7_RestingState_data.csv\n",
      "NDARWR247CE1_RestingState_data.csv\n",
      "NDARWA544RDT_RestingState_data.csv\n",
      "NDARYH110YV9_RestingState_data.csv\n",
      "NDARZR567HWG_RestingState_data.csv\n",
      "NDARXZ685TU4_RestingState_data.csv\n",
      "NDARWW901MTC_RestingState_data.csv\n",
      "NDARXF203DCD_RestingState_data.csv\n",
      "NDARYH480GTD_RestingState_data.csv\n",
      "NDARNP399JVF_RestingState_data.csv\n",
      "NDARVY054WEA_RestingState_data.csv\n",
      "NDARXF358XGE_RestingState_data.csv\n",
      "NDARYH182BBV_RestingState_data.csv\n",
      "NDARYD546HCB_RestingState_data.csv\n",
      "Done:  HBN LSTM ALL\n",
      "Synched\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import dask.dataframe as dd\n",
    "import csv\n",
    "\n",
    "# to enhance tensorflow peroformance\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "# mne base bandpass filter\n",
    "def band_pass_filter(arr,l_freq=None,h_freq=None,verbose=False):\n",
    "    montage = mne.channels.make_standard_montage(\"GSN-HydroCel-128\")\n",
    "\n",
    "    info = mne.create_info(ch_names=csv_channel_names[:len(arr)],ch_types=\"eeg\",sfreq=256,verbose=verbose)\n",
    "\n",
    "    reader = mne.io.BaseRaw(info, preload=np.array(arr,dtype=np.float64), verbose=verbose)\n",
    "\n",
    "    reader = reader.filter( l_freq=l_freq, h_freq=h_freq, picks=None,\n",
    "                            filter_length='auto',\n",
    "                                l_trans_bandwidth='auto', h_trans_bandwidth='auto', n_jobs='cuda',\n",
    "                                method='fft', iir_params=None,  phase='zero',\n",
    "                                fir_window='hamming', fir_design='firwin',\n",
    "                                pad='reflect_limited', verbose=verbose)\n",
    "    newarr, _ = reader[:]\n",
    "    return newarr\n",
    "\n",
    "# TF resizing for CNN\n",
    "def resize_cnn(x, old_shape, new_shape):\n",
    "    tmpX = np.zeros(old_shape)\n",
    "    tmpX[:,:,0] = x\n",
    "    tmpX[:,:,1] = x\n",
    "    tmpX[:,:,2] = x\n",
    "    arr = tf.image.resize(tmpX, new_shape)\n",
    "    return np.array(arr[:,:,0])\n",
    "\n",
    "\n",
    "import re\n",
    "def build(foldername, filename, outputPath,disorder):\n",
    "    # reading the file as a string and splitting it in memory seems to enhance performance\n",
    "    temp = dd.read_table(foldername + seperator + filename, sample=10000000, engine='c', header=None)\n",
    "    arr2 = temp.to_dask_array()\n",
    "    arr2 = arr2.persist()\n",
    "    arr2 = arr2.compute_chunk_sizes()\n",
    "    arr2 = [temp2[0].compute() for temp2 in arr2]\n",
    "    \n",
    "    # this is a filtering step (to exclude channel names that might have accidentally been added to the output file)\n",
    "    skipPrefix = 'E1,E2,E3,E4,E5,E6,E7,E8,E9,E10,E11,E12,E13,E14,E15,E16,E18,E19,E20,E21,E22,E23,E24,E25,E26,E27,E28,E29,E30,E31,E32,E33,E34,E35,E36,E37,E38,E39,E40,E41,E42,E44,E45,E46,E47,E50,E51,E52,E53,E54,E55,E57,E58,E59,E60,E61,E62,E64,E65,E66,E67,E69,E70,E71,E72,E74,E75,E76,E77,E78,E79,E80,E82,E83,E84,E85,E86,E87,E89,E90,E91,E92,E93,E95,E96,E97,E98,E100,E101,E102,E103,E104,E105,E106,E108,E109,E110,E111,E112,E114,E115,E116,E117,E118,E121,E122,E123,E124'\n",
    "    prefixes = skipPrefix.split(',')\n",
    "    prefixIndex = len(prefixes) - 1\n",
    "    while True:\n",
    "        cutIndex = arr2[0].rfind(prefixes[prefixIndex])\n",
    "        if cutIndex != -1:\n",
    "            cutIndex += len(prefixes[prefixIndex])\n",
    "            cutIndex += 1\n",
    "            arr2[0] = arr2[0][cutIndex:]\n",
    "            break\n",
    "        prefixIndex -= 1\n",
    "    # actual data\n",
    "    data = np.array([np.float32(temp2.split(',')) for temp2 in arr2])\n",
    "    # in case of error\n",
    "    if(len(data.shape) == 1):\n",
    "        assert False\n",
    "\n",
    "\n",
    "    # fetch length can be adjusted\n",
    "    fetch_length =  4000\n",
    "    \n",
    "    for data_counter in range((len(data[0])//fetch_length)-1):\n",
    "        for model in models.keys():\n",
    "            for freq_band in freqs.keys():\n",
    "                    input_shape = models[model]\n",
    "                    if os.path.isfile(outputPath+seperator+disorder+seperator+model+seperator+freq_band+seperator+filename.split(\".\")[0] + str(data_counter)+\".csv\"):\n",
    "                        print(\"Skipping\")\n",
    "                        continue\n",
    "                    X = np.array(data[:,data_counter*fetch_length:(data_counter+1)*fetch_length])\n",
    "                    X = band_pass_filter(X,l_freq=freqs[freq_band][0],h_freq=freqs[freq_band][1],verbose=False)\n",
    "                    X = resize_cnn(X, (len(X), fetch_length, 3), (input_shape[0], input_shape[1]))\n",
    "                    result = []\n",
    "                    for sample in range(len(X[0])):\n",
    "                        tmp = []\n",
    "                        for channel in range(len(X)):\n",
    "                            tmp.append(X[channel, sample])\n",
    "\n",
    "                        for channel in range(len(X)):\n",
    "                            if len(result) < channel + 1:\n",
    "                                result.append([])\n",
    "                            result[channel].append(tmp[channel])\n",
    "                        tmp[:] = []\n",
    "                    with open(outputPath+seperator+disorder+seperator+model+seperator+freq_band+seperator+filename.split(\".\")[0] + str(data_counter)+\".csv\", 'w',newline='') as csvfile:\n",
    "                        csvwriter = csv.writer(csvfile)\n",
    "                        for row in result:\n",
    "                            csvwriter.writerow(row)\n",
    "                    X = np.zeros((len(csv_channel_names), fetch_length))\n",
    "    print(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "retVal = []\n",
    "counter = 0\n",
    "all_counter = 0\n",
    "inputs = []\n",
    "for disorder in disorders:\n",
    "    print(disorder)\n",
    "    # make sure the output sub-diractories in the output folder are built\n",
    "    for model in models.keys():\n",
    "        for freq_band in freqs.keys():\n",
    "            for roi in roi_label:\n",
    "                if not os.path.isdir(outputPath):\n",
    "                    os.mkdir(outputPath)\n",
    "                if not os.path.isdir(outputPath+seperator+disorder):\n",
    "                    os.mkdir(outputPath+seperator+disorder)\n",
    "                if not os.path.isdir(outputPath+seperator+disorder+seperator+model):\n",
    "                    os.mkdir(outputPath+seperator+disorder+seperator+model)\n",
    "                if not os.path.isdir(outputPath+seperator+disorder+seperator+model+seperator+freq_band):\n",
    "                    os.mkdir(outputPath+seperator+disorder+seperator+model+seperator+freq_band)\n",
    "                    \n",
    "    files = os.listdir(foldername+seperator+disorder)\n",
    "    for filesname in files:\n",
    "        if os.path.isfile(foldername+seperator+disorder + seperator + filesname):\n",
    "            inputs.append((foldername+seperator+disorder, filesname, outputPath,disorder))\n",
    "            # uncomment this line to run synchronously (comment the parallel processing part as well)\n",
    "            #build(foldername+seperator+disorder, filesname, outputPath,disorder)\n",
    "\n",
    "# comment this part if you wish to disable parallel processing\n",
    "###############################\n",
    "import multiprocessing as mp\n",
    "pool = mp.Pool()\n",
    "pool.starmap(build,inputs)\n",
    "pool.close()\n",
    "pool.terminate()\n",
    "pool.join()\n",
    "###############################\n",
    "\n",
    "print(\"Done: \", disorder, model, freq_band)\n",
    "\n",
    "# necessary only for google colab, to enforce syncing google colab connection to google drive\n",
    "from google.colab import drive\n",
    "drive.flush_and_unmount()\n",
    "print(\"Synched\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPx+h0R3eTpz8HdxV5ALJna",
   "machine_shape": "hm",
   "mount_file_id": "1GRQzkzanalaiXCTK0yx6GEsvhr08C7Lc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
