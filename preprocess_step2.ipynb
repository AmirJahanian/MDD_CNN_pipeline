{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33758,
     "status": "ok",
     "timestamp": 1688826821767,
     "user": {
      "displayName": "Khaled Bagh",
      "userId": "04510009910654484115"
     },
     "user_tz": -120
    },
    "id": "kGeereC4g0UA",
    "outputId": "cc25c660-bac4-4117-b8f4-f3917bdda977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2022.12.1)\n",
      "Requirement already satisfied: distributed in /usr/local/lib/python3.10/dist-packages (2022.12.1)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask) (8.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from dask) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask) (23.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask) (6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask) (0.12.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from distributed) (3.1.2)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed) (1.0.5)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.10/dist-packages (from distributed) (5.9.5)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.10/dist-packages (from distributed) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed) (2.0.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from distributed) (6.3.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from distributed) (1.26.16)\n",
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from distributed) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->distributed) (2.1.3)\n",
      "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2022.12.1)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (23.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.22.4)\n",
      "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->dask[dataframe]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->dask[dataframe]) (2022.7.1)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=0.3.10->dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0->dask[dataframe]) (1.16.0)\n",
      "Requirement already satisfied: dask_ml in /usr/local/lib/python3.10/dist-packages (2023.3.24)\n",
      "Requirement already satisfied: dask[array,dataframe]>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (2022.12.1)\n",
      "Requirement already satisfied: distributed>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (2022.12.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (0.56.4)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (1.22.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dask_ml) (1.10.1)\n",
      "Requirement already satisfied: dask-glm>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (0.2.0)\n",
      "Requirement already satisfied: multipledispatch>=0.4.9 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (0.6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dask_ml) (23.1)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from dask-glm>=0.2.0->dask_ml) (2.2.1)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (8.1.3)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (2023.6.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.12.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (3.1.2)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (1.0.5)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (5.9.5)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (2.0.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (6.3.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (1.26.16)\n",
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (3.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from multipledispatch>=0.4.9->dask_ml) (1.16.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->dask_ml) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->dask_ml) (67.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->dask_ml) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->dask_ml) (2022.7.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask_ml) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask_ml) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->distributed>=2.4.0->dask_ml) (2.1.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.22.4)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from mne) (1.10.1)\n",
      "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.65.0)\n",
      "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.6.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (2.8.2)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.27.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
      "Requirement already satisfied: scot in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
      "Requirement already satisfied: pyprep in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from pyprep) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyprep) (1.10.1)\n",
      "Requirement already satisfied: mne>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from pyprep) (1.4.2)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from pyprep) (5.9.5)\n",
      "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mne>=0.20.0->pyprep) (3.7.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne>=0.20.0->pyprep) (4.65.0)\n",
      "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne>=0.20.0->pyprep) (1.6.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne>=0.20.0->pyprep) (4.4.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne>=0.20.0->pyprep) (23.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne>=0.20.0->pyprep) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne>=0.20.0->pyprep) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne>=0.20.0->pyprep) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne>=0.20.0->pyprep) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne>=0.20.0->pyprep) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne>=0.20.0->pyprep) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne>=0.20.0->pyprep) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne>=0.20.0->pyprep) (2.8.2)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne>=0.20.0->pyprep) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne>=0.20.0->pyprep) (2.27.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne>=0.20.0->pyprep) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne>=0.20.0->pyprep) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=0.20.0->pyprep) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=0.20.0->pyprep) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=0.20.0->pyprep) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=0.20.0->pyprep) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install dask distributed\n",
    "!pip install \"dask[dataframe]\"\n",
    "!pip install dask_ml\n",
    "!pip install h5py\n",
    "!pip install tensorflow-addons\n",
    "!pip install mne\n",
    "!pip install scot\n",
    "!pip install pyprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688826821767,
     "user": {
      "displayName": "Khaled Bagh",
      "userId": "04510009910654484115"
     },
     "user_tz": -120
    },
    "id": "k9c566xrhgcf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import datetime\n",
    "import dask\n",
    "from dask.distributed import Scheduler\n",
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from random import shuffle, seed\n",
    "import multiprocessing\n",
    "import pywt\n",
    "from scipy import fftpack\n",
    "import random\n",
    "from itertools import repeat\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import mne\n",
    "import pyprep\n",
    "import gc\n",
    "from mne.preprocessing import ICA\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency.psd import psd_array_welch\n",
    "import scot\n",
    "from pyprep.prep_pipeline import PrepPipeline\n",
    "from scipy.integrate import simps\n",
    "\n",
    "import h5py\n",
    "\n",
    "\n",
    "\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688826822273,
     "user": {
      "displayName": "Khaled Bagh",
      "userId": "04510009910654484115"
     },
     "user_tz": -120
    },
    "id": "02Y2uVNmYWmJ"
   },
   "outputs": [],
   "source": [
    "# config, is a class meant to configure the processor, in here you can specify and control the entire preprocessing steps\n",
    "\n",
    "# which disorder to process\n",
    "disorders = ['HBN', 'MDD']\n",
    "\n",
    "class config(object):\n",
    "    def __init__(self):\n",
    "        # folder name were the data should be read\n",
    "        self.foldername = r''\n",
    "        # leave empty\n",
    "        self.datapath = ''\n",
    "        # folder name where the results should be stored\n",
    "        self.resultpath =r''\n",
    "        # required for processing (do not remove)\n",
    "        self.filename = \"\"\n",
    "        # lower and upper frequency for band pass filter\n",
    "        self.band_pass_filter = [1,70]\n",
    "        # csv channels names. Required for some preprocessing steps (specific to HBN, do not change)\n",
    "        self.csv_channel_names = ['E1','E2',\\\n",
    "                                  'E3','E4','E5','E6','E7','E8','E9','E10','E11','E12','E13','E14','E15','E16','E18','E19','E20','E21','E22','E23','E24','E25',\\\n",
    "                                  'E26','E27','E28','E29','E30','E31','E32','E33','E34','E35','E36','E37','E38','E39','E40','E41','E42','E44','E45','E46','E47',\\\n",
    "                                  'E50','E51','E52','E53','E54','E55','E57','E58','E59','E60','E61','E62','E64','E65','E66','E67','E69','E70','E71','E72','E74','E75',\\\n",
    "                                  'E76','E77','E78','E79','E80','E82','E83','E84','E85','E86','E87','E89','E90','E91','E92','E93','E95','E96','E97','E98','E100','E101',\\\n",
    "                                  'E102','E103','E104','E105','E106','E108','E109','E110','E111','E112','E114','E115','E116','E117','E118','E121','E122','E123','E124']\n",
    "        # channels that EOG and ECG should be applied to (recommended to apply to all channels)\n",
    "        self.ECG_channel =self.csv_channel_names\n",
    "        self.EOG_channel = self.csv_channel_names\n",
    "        \n",
    "        # Wanted channels, will exclude any other channel in the data\n",
    "        self.wanted_channels = self.csv_channel_names\n",
    "        # original frequency\n",
    "        self.sfreq = 500\n",
    "        #resampiling frequency\n",
    "        self.resample_freq = 256\n",
    "        # Notch filter frequncy\n",
    "        self.notch_frequncy = 60\n",
    "        # psd resolution, which is the number of sample used in the psd computation\n",
    "        # a large value would give a lot of noise, a low value will start to lose information\n",
    "        # this is optimized manually by testing the output\n",
    "        self.psd_resolution = 2500\n",
    "        # percentage of overlap for PSD segments (to reduce noise)\n",
    "        self.overlap_percentage = 0.5\n",
    "\n",
    "        # motange is the channels standered positining (read the comment below for all options)\n",
    "        self.montage = \"GSN-HydroCel-128\"\n",
    "        '''\n",
    "        standard_1005\n",
    "\n",
    "        Electrodes are named and positioned according to the international 10-05 system (343+3 locations)\n",
    "\n",
    "        standard_1020\n",
    "\n",
    "        Electrodes are named and positioned according to the international 10-20 system (94+3 locations)\n",
    "\n",
    "        standard_alphabetic\n",
    "\n",
    "        Electrodes are named with LETTER-NUMBER combinations (A1, B2, F4, …) (65+3 locations)\n",
    "\n",
    "        standard_postfixed\n",
    "\n",
    "        Electrodes are named according to the international 10-20 system using postfixes for intermediate positions (100+3 locations)\n",
    "\n",
    "        standard_prefixed\n",
    "\n",
    "        Electrodes are named according to the international 10-20 system using prefixes for intermediate positions (74+3 locations)\n",
    "\n",
    "        standard_primed\n",
    "\n",
    "        Electrodes are named according to the international 10-20 system using prime marks (’ and ‘’) for intermediate positions (100+3 locations)\n",
    "\n",
    "        biosemi16\n",
    "\n",
    "        BioSemi cap with 16 electrodes (16+3 locations)\n",
    "\n",
    "        biosemi32\n",
    "\n",
    "        BioSemi cap with 32 electrodes (32+3 locations)\n",
    "\n",
    "        biosemi64\n",
    "\n",
    "        BioSemi cap with 64 electrodes (64+3 locations)\n",
    "\n",
    "        biosemi128\n",
    "\n",
    "        BioSemi cap with 128 electrodes (128+3 locations)\n",
    "\n",
    "        biosemi160\n",
    "\n",
    "        BioSemi cap with 160 electrodes (160+3 locations)\n",
    "\n",
    "        biosemi256\n",
    "\n",
    "        BioSemi cap with 256 electrodes (256+3 locations)\n",
    "\n",
    "        easycap-M1\n",
    "\n",
    "        EasyCap with 10-05 electrode names (74 locations)\n",
    "\n",
    "        easycap-M10\n",
    "\n",
    "        EasyCap with numbered electrodes (61 locations)\n",
    "\n",
    "        EGI_256\n",
    "\n",
    "        Geodesic Sensor Net (256 locations)\n",
    "\n",
    "        GSN-HydroCel-32\n",
    "\n",
    "        HydroCel Geodesic Sensor Net and Cz (33+3 locations)\n",
    "\n",
    "        GSN-HydroCel-64_1.0\n",
    "\n",
    "        HydroCel Geodesic Sensor Net (64+3 locations)\n",
    "\n",
    "        GSN-HydroCel-65_1.0\n",
    "\n",
    "        HydroCel Geodesic Sensor Net and Cz (65+3 locations)\n",
    "\n",
    "        GSN-HydroCel-128\n",
    "\n",
    "        HydroCel Geodesic Sensor Net (128+3 locations)\n",
    "\n",
    "        GSN-HydroCel-129\n",
    "\n",
    "        HydroCel Geodesic Sensor Net and Cz (129+3 locations)\n",
    "\n",
    "        GSN-HydroCel-256\n",
    "\n",
    "        HydroCel Geodesic Sensor Net (256+3 locations)\n",
    "\n",
    "        GSN-HydroCel-257\n",
    "\n",
    "        HydroCel Geodesic Sensor Net and Cz (257+3 locations)\n",
    "\n",
    "        mgh60\n",
    "\n",
    "        The (older) 60-channel cap used at MGH (60+3 locations)\n",
    "\n",
    "        mgh70\n",
    "\n",
    "        The (newer) 70-channel BrainVision cap used at MGH (70+3 locations)\n",
    "\n",
    "        artinis-octamon\n",
    "\n",
    "        Artinis OctaMon fNIRS (8 sources, 2 detectors)\n",
    "\n",
    "        artinis-brite23\n",
    "\n",
    "        Artinis Brite23 fNIRS (11 sources, 7 detectors)\n",
    "        '''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1688826822274,
     "user": {
      "displayName": "Khaled Bagh",
      "userId": "04510009910654484115"
     },
     "user_tz": -120
    },
    "id": "Xf_wDY4oYgbi"
   },
   "outputs": [],
   "source": [
    "\"\"\"Module for PREP pipeline.\"\"\"\n",
    "# this module is copied from prep pipeline offical code, slightly adjusted to out need in this pipeline\n",
    "import mne\n",
    "from mne.utils import check_random_state\n",
    "\n",
    "from pyprep.find_noisy_channels import NoisyChannels\n",
    "from pyprep.reference import Reference\n",
    "from pyprep.removeTrend import removeTrend\n",
    "from pyprep.utils import _set_diff, _union  # noqa: F401\n",
    "\n",
    "\n",
    "\n",
    "class PrepPipeline:\n",
    "    \"\"\"Early stage preprocessing (PREP) of EEG data.\n",
    "\n",
    "    This class implements the functionality  of the PREP (preprocessing\n",
    "    pipeline) for EEG data described in [1]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw : mne.io.Raw\n",
    "        The data. Channel types must be correctly assigned (e.g.,\n",
    "        ocular channels are assigned the type 'eog').\n",
    "    prep_params : dict\n",
    "        Parameters of PREP which include at least the following keys:\n",
    "\n",
    "        - ref_chs : {list, 'eeg'}\n",
    "            - A list of channel names to be used for rereferencing.\n",
    "              Can be a str 'eeg' to use all EEG channels.\n",
    "        - reref_chs : {list, 'eeg'}\n",
    "            - A list of channel names to be used for line-noise removed,\n",
    "              and referenced. Can be a str 'eeg' to use all EEG channels.\n",
    "        - line_freqs : {np.ndarray, list}\n",
    "            - list of floats indicating frequencies to be removed.\n",
    "              For example, for 60Hz you may specify\n",
    "              ``np.arange(60, sfreq / 2, 60)``. Specify an empty list to\n",
    "              skip the line noise removal step.\n",
    "        - max_iterations : int, optional\n",
    "            - The maximum number of iterations of noisy channel removal to\n",
    "              perform during robust referencing. Defaults to ``4``.\n",
    "    montage : mne.channels.DigMontage\n",
    "        Digital montage of EEG data.\n",
    "    ransac : bool, optional\n",
    "        Whether or not to use RANSAC for noisy channel detection in addition to\n",
    "        the other methods in :class:`~pyprep.NoisyChannels`. Defaults to True.\n",
    "    channel_wise : bool, optional\n",
    "        Whether RANSAC should predict signals for chunks of channels over the\n",
    "        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n",
    "        parameter). If ``False``, RANSAC will instead predict signals for all\n",
    "        channels at once but over a number of smaller time windows instead of\n",
    "        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n",
    "        RANSAC generally has higher RAM demands than window-wise RANSAC\n",
    "        (especially if `max_chunk_size` is ``None``), but can be faster on\n",
    "        systems with lots of RAM to spare. Has no effect if not using RANSAC.\n",
    "        Defaults to ``False``.\n",
    "    max_chunk_size : {int, None}, optional\n",
    "        The maximum number of channels to predict at once during channel-wise\n",
    "        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n",
    "        fit into the available RAM, which may slow down other programs on the\n",
    "        host system. If using window-wise RANSAC (the default) or not using\n",
    "        RANSAC at all, this parameter has no effect. Defaults to ``None``.\n",
    "    random_state : {int, None, np.random.RandomState}, optional\n",
    "        The random seed at which to initialize the class. If random_state is\n",
    "        an int, it will be used as a seed for RandomState.\n",
    "        If None, the seed will be obtained from the operating system\n",
    "        (see RandomState for details). Default is None.\n",
    "    filter_kwargs : {dict, None}, optional\n",
    "        Optional keywords arguments to be passed on to mne.filter.notch_filter.\n",
    "        Do not set the \"x\", Fs\", and \"freqs\" arguments via the filter_kwargs\n",
    "        parameter, but use the \"raw\" and \"prep_params\" parameters instead.\n",
    "        If None is passed, the pyprep default settings for filtering are used\n",
    "        instead.\n",
    "    matlab_strict : bool, optional\n",
    "        Whether or not PyPREP should strictly follow MATLAB PREP's internal\n",
    "        math, ignoring any improvements made in PyPREP over the original code\n",
    "        (see :ref:`matlab-diffs` for more details). Defaults to False.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    raw : mne.io.Raw\n",
    "        The data including eeg and non eeg channels. It is unprocessed if\n",
    "        accessed before the fit method, processed if accessed after a\n",
    "        successful fit method.\n",
    "    raw_eeg : mne.io.Raw\n",
    "        The only-eeg part of the data. It is unprocessed if accessed before\n",
    "        the fit method, processed if accessed after a successful fit method.\n",
    "    raw_non_eeg : {mne.io.Raw, None}\n",
    "        The non-eeg part of the data. It is not processed when calling\n",
    "        the fit method. If the input was only EEG it will be None.\n",
    "    noisy_channels_original : dict\n",
    "       Detailed bad channels in each criteria before robust reference.\n",
    "    noisy_channels_before_interpolation : dict\n",
    "        Detailed bad channels in each criteria just before interpolation.\n",
    "    noisy_channels_after_interpolation : dict\n",
    "        Detailed bad channels in each criteria just after interpolation.\n",
    "    bad_before_interpolation : list\n",
    "        bad channels after robust reference but before interpolation\n",
    "    EEG_before_interpolation : np.ndarray\n",
    "        EEG data in uV before the interpolation\n",
    "    reference_before_interpolation : np.ndarray\n",
    "        Reference signal in uV before interpolation.\n",
    "    reference_after_interpolation : np.ndarray\n",
    "        Reference signal in uV after interpolation.\n",
    "    interpolated_channels : list\n",
    "        Names of the interpolated channels.\n",
    "    still_noisy_channels : list\n",
    "        Names of the noisy channels after interpolation.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K. M., Robbins, K. A.\n",
    "       (2015). The PREP pipeline: standardized preprocessing for large-scale\n",
    "       EEG analysis. Frontiers in Neuroinformatics, 9, 16.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        raw,\n",
    "        prep_params,\n",
    "        montage,\n",
    "        ransac=True,\n",
    "        channel_wise=False,\n",
    "        max_chunk_size=None,\n",
    "        random_state=None,\n",
    "        filter_kwargs=None,\n",
    "        matlab_strict=False,\n",
    "    ):\n",
    "        \"\"\"Initialize PREP class.\"\"\"\n",
    "        raw.load_data()\n",
    "        self.raw_eeg = raw.copy()\n",
    "\n",
    "        # split eeg and non eeg channels\n",
    "        self.ch_names_all = raw.ch_names.copy()\n",
    "        self.ch_types_all = raw.get_channel_types()\n",
    "        self.ch_names_eeg = [\n",
    "            self.ch_names_all[i]\n",
    "            for i in range(len(self.ch_names_all))\n",
    "            if self.ch_types_all[i] == \"eeg\"\n",
    "        ]\n",
    "        self.ch_names_non_eeg = list(set(self.ch_names_all) - set(self.ch_names_eeg))\n",
    "        self.raw_eeg.pick_channels(self.ch_names_eeg)\n",
    "        if self.ch_names_non_eeg == []:\n",
    "            self.raw_non_eeg = None\n",
    "        else:\n",
    "            self.raw_non_eeg = raw.copy()\n",
    "            self.raw_non_eeg.pick_channels(self.ch_names_non_eeg)\n",
    "\n",
    "        self.raw_eeg.set_montage(montage,on_missing='ignore')\n",
    "        # raw_non_eeg may not be compatible with the montage\n",
    "        # so it is not set for that object\n",
    "\n",
    "        self.EEG_raw = self.raw_eeg.get_data()\n",
    "        self.prep_params = prep_params\n",
    "        if self.prep_params[\"ref_chs\"] == \"eeg\":\n",
    "            self.prep_params[\"ref_chs\"] = self.ch_names_eeg\n",
    "        if self.prep_params[\"reref_chs\"] == \"eeg\":\n",
    "            self.prep_params[\"reref_chs\"] = self.ch_names_eeg\n",
    "        if \"max_iterations\" not in prep_params.keys():\n",
    "            self.prep_params[\"max_iterations\"] = 4\n",
    "        self.sfreq = self.raw_eeg.info[\"sfreq\"]\n",
    "        self.ransac_settings = {\n",
    "            \"ransac\": ransac,\n",
    "            \"channel_wise\": channel_wise,\n",
    "            \"max_chunk_size\": max_chunk_size,\n",
    "        }\n",
    "        self.random_state = check_random_state(random_state)\n",
    "        self.filter_kwargs = filter_kwargs\n",
    "        self.matlab_strict = matlab_strict\n",
    "\n",
    "    @property\n",
    "    def raw(self):\n",
    "        \"\"\"Return a version of self.raw_eeg that includes the non-eeg channels.\"\"\"\n",
    "        full_raw = self.raw_eeg.copy()\n",
    "        if self.raw_non_eeg is None:\n",
    "            return full_raw\n",
    "        else:\n",
    "            return full_raw.add_channels([self.raw_non_eeg], force_update_info=True)\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Run the whole PREP pipeline.\"\"\"\n",
    "        noisy_detector = NoisyChannels(self.raw_eeg, random_state=self.random_state)\n",
    "        noisy_detector.find_bad_by_nan_flat()\n",
    "        # unusable_channels = _union(\n",
    "        #     noisy_detector.bad_by_nan, noisy_detector.bad_by_flat\n",
    "        # )\n",
    "        # reference_channels = _set_diff(self.prep_params[\"ref_chs\"], unusable_channels)\n",
    "        # Step 1: 1Hz high pass filtering\n",
    "        if len(self.prep_params[\"line_freqs\"]) != 0:\n",
    "            self.EEG_new = removeTrend(\n",
    "                self.EEG_raw, self.sfreq, matlab_strict=self.matlab_strict\n",
    "            )\n",
    "\n",
    "            # Step 2: Removing line noise\n",
    "            linenoise = self.prep_params[\"line_freqs\"]\n",
    "            if self.filter_kwargs is None:\n",
    "                self.EEG_clean = mne.filter.notch_filter(\n",
    "                    self.EEG_new,\n",
    "                    Fs=self.sfreq,\n",
    "                    freqs=linenoise,\n",
    "                    method=\"spectrum_fit\",\n",
    "                    mt_bandwidth=2,\n",
    "                    p_value=0.01,\n",
    "                    filter_length=\"10s\",\n",
    "                )\n",
    "            else:\n",
    "                self.EEG_clean = mne.filter.notch_filter(\n",
    "                    self.EEG_new,\n",
    "                    Fs=self.sfreq,\n",
    "                    freqs=linenoise,\n",
    "                    **self.filter_kwargs,\n",
    "                )\n",
    "\n",
    "            # Add Trend back\n",
    "            self.EEG = self.EEG_raw - self.EEG_new + self.EEG_clean\n",
    "            self.raw_eeg._data = self.EEG\n",
    "\n",
    "        # Step 3: Referencing\n",
    "        reference = Reference(\n",
    "            self.raw_eeg,\n",
    "            self.prep_params,\n",
    "            random_state=self.random_state,\n",
    "            matlab_strict=self.matlab_strict,\n",
    "            **self.ransac_settings,\n",
    "        )\n",
    "        reference.perform_reference(self.prep_params[\"max_iterations\"])\n",
    "        self.raw_eeg = reference.raw\n",
    "        self.noisy_channels_original = reference.noisy_channels_original\n",
    "        self.noisy_channels_before_interpolation = (\n",
    "            reference.noisy_channels_before_interpolation\n",
    "        )\n",
    "        self.noisy_channels_after_interpolation = (\n",
    "            reference.noisy_channels_after_interpolation\n",
    "        )\n",
    "        self.bad_before_interpolation = reference.bad_before_interpolation\n",
    "        self.EEG_before_interpolation = reference.EEG_before_interpolation\n",
    "        self.reference_before_interpolation = reference.reference_signal\n",
    "        self.reference_after_interpolation = reference.reference_signal_new\n",
    "        self.interpolated_channels = reference.interpolated_channels\n",
    "        self.still_noisy_channels = reference.still_noisy_channels\n",
    "\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688826822274,
     "user": {
      "displayName": "Khaled Bagh",
      "userId": "04510009910654484115"
     },
     "user_tz": -120
    },
    "id": "M-rd3pFzWfxj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688826822275,
     "user": {
      "displayName": "Khaled Bagh",
      "userId": "04510009910654484115"
     },
     "user_tz": -120
    },
    "id": "6NGyE3WCYTGS"
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import dask.dataframe as dd\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "def get_diractory_seperator_type():\n",
    "\t  # type pf seperator between each folder in the path\n",
    "    if platform == \"linux\":\n",
    "        seperator = \"/\"\n",
    "    elif platform == 'win32':\n",
    "        seperator = '\\\\'\n",
    "    else:\n",
    "        exit(0)\n",
    "    return seperator\n",
    "\n",
    "seperator = get_diractory_seperator_type()\n",
    "\n",
    "# deprecated\n",
    "lock = threading.Lock()\n",
    "lock_conn = threading.Lock()\n",
    "\n",
    "class EEG_file_processor():\n",
    "    def __init__(self, config, disorder):\n",
    "        if(os.path.isdir(config.datapath)):\n",
    "            self.datapath = config.datapath\n",
    "        else:\n",
    "            raise Exception(\"File path is not vaild: \"+config.datapath)\n",
    "\n",
    "        if(os.path.isdir(config.resultpath)):\n",
    "            self.resultpath = config.resultpath\n",
    "        else:\n",
    "            raise Exception(\"Result path is not vaild: \"+config.resultpath)\n",
    "\n",
    "        self.filename = config.filename\n",
    "        self.disorder = disorder\n",
    "\n",
    "        self.band_pass_filter = config.band_pass_filter\n",
    "        self.csv_channel_names = config.csv_channel_names\n",
    "        self.sfreq = config.sfreq\n",
    "        self.resample_freq = config.resample_freq\n",
    "        self.notch_frequncy = config.notch_frequncy\n",
    "        self.psd_resolution = config.psd_resolution\n",
    "        self.overlap_percentage = config.overlap_percentage\n",
    "        self.montage = config.montage\n",
    "\n",
    "        self.ECG_channel = config.ECG_channel\n",
    "        self.EOG_channel = config.EOG_channel\n",
    "        \n",
    "        # object to hold data\n",
    "        self.reader = None\n",
    "\n",
    "        self.fill_readers()\n",
    "        self.Build_dirs()\n",
    "        gc.collect()\n",
    "\n",
    "    def band_pass_filter(self,l_freq=None,h_freq=None,verbose=False):\n",
    "        if h_freq == None or l_freq ==None:\n",
    "            self.reader = self.reader.filter( l_freq=self.band_pass_filter[0], h_freq=self.band_pass_filter[1], picks=None,\n",
    "                            filter_length='auto',\n",
    "                                l_trans_bandwidth='auto', h_trans_bandwidth='auto', n_jobs=1,\n",
    "                                method='fft', iir_params=None,  phase='zero',\n",
    "                                fir_window='hamming', fir_design='firwin',\n",
    "                                pad='reflect_limited', verbose=verbose)\n",
    "            gc.collect()\n",
    "            return None\n",
    "        else:\n",
    "            #retVal = mne.filter.filter_data(self.reader,sfreq=self.resample_freq, l_freq=l_freq, h_freq=h_freq)\n",
    "            newreader = self.reader.copy()\n",
    "            newreader.filter( l_freq=l_freq, h_freq=h_freq, picks=None,\n",
    "                            filter_length='auto',\n",
    "                                l_trans_bandwidth='auto', h_trans_bandwidth='auto', n_jobs=1,\n",
    "                                method='fft', iir_params=None,  phase='zero',\n",
    "                                fir_window='hamming', fir_design='firwin',\n",
    "                                pad='reflect_limited', verbose=verbose)\n",
    "            gc.collect()\n",
    "            return newreader[:]\n",
    "\n",
    "\n",
    "    def notch_filter(self,verbose=False):\n",
    "        self.reader = self.reader.notch_filter(freqs=self.notch_frequncy, picks=None, filter_length='auto',\n",
    "                         notch_widths=None, trans_bandwidth=1.0, n_jobs=1,\n",
    "                         method='fir', iir_params=None, mt_bandwidth=None,\n",
    "                         p_value=0.05, phase='zero', fir_window='hamming',\n",
    "                         fir_design='firwin', pad='reflect_limited', verbose=verbose)\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    # mathod can be infomax or fastica\n",
    "    def ICA(self,method='fastica',remove_movement= True):\n",
    "        self.remove_nan()\n",
    "        self.remove_muscle_movment()\n",
    "        ica = ICA(n_components=len(self.reader.ch_names)-len(self.reader.info['bads'])-1, method=method, random_state=0)\n",
    "        ica.fit(self.reader)\n",
    "        for channel_name in self.ECG_channel:\n",
    "            if channel_name in self.reader.ch_names:\n",
    "                ecg_annot,_ = ica.find_bads_ecg(self.reader, ch_name=channel_name, threshold='auto', start=None,\n",
    "                              stop=None, l_freq=self.band_pass_filter[0], h_freq=self.band_pass_filter[1], method='correlation',\n",
    "                              reject_by_annotation=True, measure='zscore',\n",
    "                              verbose=None)\n",
    "        for channel_name in self.EOG_channel:\n",
    "            if channel_name in self.reader.ch_names:\n",
    "                eog_annot,_ = ica.find_bads_eog(self.reader, ch_name=channel_name, threshold=3.0, start=None,\n",
    "                              stop=None, l_freq=self.band_pass_filter[0], h_freq=self.band_pass_filter[1],\n",
    "                              reject_by_annotation=True, measure='zscore',\n",
    "                              verbose=None)\n",
    "\n",
    "        self.reader = ica.apply(self.reader, n_pca_components=len(self.reader.ch_names)-len(self.reader.info['bads'])-1)\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    def Interpolate(self):\n",
    "        self.reader = self.reader.copy().interpolate_bads(reset_bads=False)\n",
    "\n",
    "    def remove_muscle_movment(self):\n",
    "        annot, _ = mne.preprocessing.artifact_detection.annotate_muscle_zscore(self.reader, threshold=5, ch_type=\"eeg\", min_length_good=0.1,\n",
    "                           filter_freq=(110, 140]), n_jobs=1, verbose=None)\n",
    "        self.reader.set_annotations(annot)\n",
    "    def remove_nan(self):\n",
    "        annot = mne.preprocessing.annotate_nan(self.reader)\n",
    "        self.reader.set_annotations(annot)\n",
    "\n",
    "\n",
    "\n",
    "    def fill_readers(self, verbose=True):\n",
    "        temp = dd.read_table(self.datapath + seperator + self.filename,sample=10000000, engine='c')\n",
    "        arr2 = temp.to_dask_array()\n",
    "        arr2 = arr2.persist()\n",
    "        arr2 = arr2.compute_chunk_sizes()\n",
    "        df = np.array([np.float32((temp2[0].compute()).split(',')) for temp2 in arr2])\n",
    "        print(\"df.shape\", df.shape)\n",
    "        #df = pd.read_csv(self.datapath + seperator + self.filename)\n",
    "        montage = mne.channels.make_standard_montage(self.montage)\n",
    "        tmp_ch_pos = montage.get_positions()\n",
    "\n",
    "        info = mne.create_info(ch_names=list(tmp_ch_pos[\"ch_pos\"].keys()),ch_types=\"eeg\",sfreq=self.sfreq,verbose=verbose)\n",
    "\n",
    "        self.reader = mne.io.BaseRaw(info, preload=np.array(df,dtype=np.float64), verbose=verbose)\n",
    "        self.reader.set_montage(montage)\n",
    "        data, _ = self.reader[:]\n",
    "\n",
    "        if 'Cz' in self.reader.ch_names:\n",
    "            self.reader = self.reader.drop_channels(['Cz'])\n",
    "        print(self.datapath + seperator +self.filename)\n",
    "        data, _ = self.reader[:]\n",
    "        for index, channel in enumerate(self.reader.ch_names):\n",
    "            if all(data[index]) == 0:\n",
    "                self.reader = self.reader.drop_channels(channel)\n",
    "        for index, channel in enumerate(self.reader.ch_names):\n",
    "            if channel not in self.csv_channel_names:\n",
    "                self.reader = self.reader.drop_channels([channel])\n",
    "\n",
    "\n",
    "        data, _ = self.reader[:]\n",
    "        print(len(self.reader.ch_names), len(data))\n",
    "\n",
    "\n",
    "        self.prep_pipeline()\n",
    "        self.reader.resample(sfreq=self.resample_freq)\n",
    "\n",
    "        filename = self.filename.split(\".\")[0] + \".h5\"\n",
    "        if(not os.path.isdir(self.resultpath+seperator+self.disorder)):\n",
    "            os.mkdir(self.resultpath+seperator+self.disorder)\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "    def rereference(self, verbose = False):\n",
    "        mne.io.set_eeg_reference(self.reader, ref_channels='average', copy=False, \\\n",
    "                            projection=False, ch_type='auto', forward=None,\\\n",
    "                          verbose=verbose)\n",
    "\n",
    "    def savestep1(self):\n",
    "        data, time = self.reader[:]\n",
    "        result = [list(self.reader.ch_names)]\n",
    "        annotations = self.reader.annotations\n",
    "        for sample in range(len(data[0])):\n",
    "            tmp = []\n",
    "            for channel in range(len(data)):\n",
    "                tmp.append(data[channel, sample])\n",
    "\n",
    "            for channel in range(len(data)):\n",
    "                if len(result) < channel + 1:\n",
    "                    result.append([])\n",
    "                result[channel].append(tmp[channel])\n",
    "            tmp[:] = []\n",
    "\n",
    "        with open(self.resultpath+seperator+self.disorder+seperator+self.filename, 'w',newline='') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            for row in result:\n",
    "                csvwriter.writerow(row)\n",
    "\n",
    "    def Build_dirs(self):\n",
    "        if(not os.path.isdir(self.resultpath+seperator+self.disorder)):\n",
    "            os.mkdir(self.resultpath+seperator+self.disorder)\n",
    "        if not os.path.isdir(self.resultpath+seperator+self.disorder+seperator+'CNN'):\n",
    "            os.mkdir(self.resultpath+seperator+self.disorder+seperator+'CNN')\n",
    "\n",
    "        if not os.path.isdir(self.resultpath+seperator+self.disorder+seperator+'LSTM'):\n",
    "            os.mkdir(self.resultpath+seperator+self.disorder+seperator+'LSTM')\n",
    "\n",
    "    def prep_pipeline(self):\n",
    "        prep_params = {\n",
    "            \"ref_chs\": \"eeg\",\n",
    "            \"reref_chs\": \"eeg\",\n",
    "            \"line_freqs\": np.array([self.notch_frequncy]),\n",
    "            \"max_iterations\": 3\n",
    "        }\n",
    "        #\"line_freqs\": np.array([self.notch_frequncy]),\n",
    "        failed = False\n",
    "        try:\n",
    "            prep = PrepPipeline(self.reader.copy(),\n",
    "                                prep_params,\n",
    "                                self.montage,\n",
    "                                ransac=True,\n",
    "                                channel_wise=False,\n",
    "                                max_chunk_size=self.sfreq*2,\n",
    "                                random_state=0,\n",
    "                                filter_kwargs=None,\n",
    "                                matlab_strict=True)\n",
    "            prep.fit()\n",
    "        except Exception as e:\n",
    "            print(\"Failed in prep\")\n",
    "            failed = True\n",
    "        if failed:\n",
    "            prep = PrepPipeline(self.reader.copy(),\n",
    "                                    prep_params,\n",
    "                                    self.montage,\n",
    "                                    ransac=False,\n",
    "                                    channel_wise=False,\n",
    "                                    max_chunk_size=self.sfreq*2,\n",
    "                                    random_state=0,\n",
    "                                    filter_kwargs=None,\n",
    "                                    matlab_strict=True)\n",
    "            prep.fit()\n",
    "\n",
    "        self.reader.info['bads'].extend(prep.noisy_channels_original[\"bad_all\"])\n",
    "        self.reader.info['bads'].extend(prep.still_noisy_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9hMm1FnT7gt",
    "outputId": "3adb4b27-0d5d-4af7-9d48-2490f4f15eb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting program\n",
      "HBN\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "df.shape (128, 305856)\n",
      "/content/drive/MyDrive/MDD/data/pre_processed/original_data/HBN/NDARGD507TDZ_RestingState_data.csv\n",
      "107 107\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 1651 samples (3.302 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 107 out of 107 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed notch frequencies (Hz):\n",
      "     60.00 : 12947 windows\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_files(Config,disorder):\n",
    "    try:\n",
    "        processor = EEG_file_processor(Config,disorder)\n",
    "        processor.band_pass_filter()\n",
    "        processor.notch_filter()\n",
    "        processor.Interpolate()\n",
    "        processor.rereference()\n",
    "        processor.ICA()\n",
    "        print(\"########################################################################################################################\")\n",
    "        print(\"saving\")\n",
    "        print(\"########################################################################################################################\")\n",
    "        processor.savestep1()\n",
    "\n",
    "        print(\"########################################################################################################################\")\n",
    "        print(\"done\")\n",
    "        print(\"########################################################################################################################\")\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_tb(e.__traceback__)\n",
    "        print(Config.filename + \" # \" + disorder + \" , Error: \" + str(e) + \"\\n\")\n",
    "        return Config.filename + \" # \" + disorder + \" , Error: \" + str(e) + \"\\n\"\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    Config = config()\n",
    "\n",
    "    # work with the file as it is now locked\n",
    "    if os.path.isfile(\"/content/drive/MyDrive/MDD/data/pre_processed/processed_files.txt\"):\n",
    "        file = open(\"/content/drive/MyDrive/MDD/data/pre_processed/processed_files.txt\", \"r\")\n",
    "        lines = file.readlines().copy()\n",
    "        file.close()\n",
    "    else:\n",
    "        with open(\"/content/drive/MyDrive/MDD/data/pre_processed/processed_files.txt\", 'w') as f:\n",
    "            print('Create a new text file!')\n",
    "        lines = []\n",
    "    retVal = []\n",
    "    limit_counter= 0\n",
    "    counter = 0\n",
    "    all_counter = 0\n",
    "    inputs = []\n",
    "    for disorder in disorders:\n",
    "        print(disorder)\n",
    "        files = os.listdir(Config.foldername+disorder)\n",
    "        for filesname in files:\n",
    "            all_counter += 1\n",
    "            file_config = config()\n",
    "            file_config.filename = filesname\n",
    "            file_config.datapath = Config.foldername+disorder\n",
    "            found = False\n",
    "            try:\n",
    "                os.mkdir(Config.resultpath+disorder)\n",
    "            except Exception as e:\n",
    "                lines = []\n",
    "\n",
    "            #process_files(file_config,disorder)\n",
    "            #break\n",
    "            inputs.append((file_config,disorder))\n",
    "            counter += 1\n",
    "            print(counter)\n",
    "\n",
    "\n",
    "    import multiprocessing as mp\n",
    "    pool = mp.Pool()\n",
    "    retVal.extend(list(pool.starmap(process_files,inputs)))\n",
    "    pool.close()\n",
    "    pool.terminate()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Failed files:\")\n",
    "    for ret in retVal:\n",
    "      print(ret)\n",
    "\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    print(\"Starting program\")\n",
    "    main()\n",
    "    print('Done excuting')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM2Cq2GDYEa+MnVGcctSczK",
   "machine_shape": "hm",
   "mount_file_id": "16q0IQVDjEVAivaBu_SmXYLe5fu32oPyS",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
